\documentclass{article}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath} % or simply amstext
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage[export]{adjustbox}
\newcommand{\angstrom}{\textup{\AA}}
\newcommand{\colormap}{jet}  % colorbar to use
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{gensymb}
\usepackage{float}

%Predicting Flux and Selectivity of Solutes in a Nanostructured Membrane using the Infinite Hidden Markov Model
\title{Stochastic Models Parameterized by the Infinite Hidden Markov Model Can Predict Flux and Selectivity of Solutes in Nanostructured Membranes.}
%MRS: a little overly specific? Maybe something like below?
%\title{Statistical inference of mechanism and long time scale behavior from timeseries of solute trajectories in nanostructured membranes}

\author{Benjamin J. Coscia, Christopher P. Calderon \and Michael R. Shirts} 

\begin{document}

  \graphicspath{{./figures/}}
  \maketitle

  \section{Introduction}
  
  We need highly selective membranes in order to perform efficient separations. \\

  \noindent Amphiphilic molecules are capable of self-assembling into ordered nanostructures.\\

  Lyotropic liquid crystals are a class of amphiphilic molecules that can be cross-linked
  into mechanically strong membranes.\\
%  \begin{itemize}
%  	\item H\textsubscript{II} phase lyotropic liquid crystals have densely packed, uniform
%	sized pores and have the potential to disrupt conventional membrane separation
%	techniques by being selective based not only on size and charge, but on chemical
%	functionality as well.
%	\item Q\textsubscript{I} phase LLCs consist of a tortuous network of 3D interconnected
%	pores. They are easier to make.
%  \end{itemize}

  %MRS: tweak phrasing.
  %We can only learn so much from experiment. 
  There are limits to what we can learn from experiment.
  MD can give us mechanistic insights with
  atomistic resolution so that we can intelligently design new membranes for 
  solute-specific separations.\\

  Unfortunately, the timescales that we can simulate with MD are insufficient to be
  able to make well-converged predictions of macroscopic transport properties 
  traditionally used to characterize membranes in the lab.
  \begin{itemize}
    \item However, if we use descriptive stochastic models that can capture solute
    dynamics, then we could project long timescale behavior in addition to gaining
    a deeper understanding of solute behavior on short timescales.
  \end{itemize}
  
  In our previous work, we designed two different approaches which used
  solute time series in order to parameterize stochastic models that could be used
  to project transport on much longer timescales.
  \begin{itemize}
  	\item Brief description of anomalous diffusion
  	\item Brief description of MSDDM
  \end{itemize}
  
  Although both models had reasonable success at predicting solute MSDs on simulation
  timescales, they had shortcomings.
  \begin{itemize}
  	\item Why MSDDM failed
  	\item Why anomalous diffusion model could be better.
  \end{itemize}
  
  % BJC: Not sure whether to call it the infinite hidden markov model or hierarchical dirichlet process hidden markov model
  % The former is definitely simpler.
  % MRS: True.  I would probably see which is used more in the literature. 
  In this work, we apply the infinite hidden markov model (iHMM), a modeling
  approach that is agnostic to the source of time series data, in order to 
  automatically detect and infer the parameters of an unknown number of latent
  autoregressive modes. \\
  
  We study the same four solutes from our previous work. \\
  
  We use the iHMM to generate stochastic trajectory realizations that share the same
  dynamical characteristics as solute trajectories observed in our MD simulations. 
  \begin{itemize}
    \item The trajectories are qualitatively similar, showing expected hopping and trapping
    behavior
    \item They are quantitatively similar in that they reproduce the MSDs measured in MD
  \end{itemize}

  %MRS: we talked about inferring mechanisms from the trajectories (i.e. looking at the states 
  %that were automatically identfied and seeing how those compared to previous studies)
  %MRS: you do talk about it at the end - it should be discussed here as well (ask all the questions you are going to answer)  
  %MRS: discuss the types of comparison you could do (though some details would be in methods

  Finally, we use the stochastic trajectory realizations in order to compute the MFPT 
  of solutes in macroscopic length pores.
  \begin{itemize}
  	\item We relate the MFPT to flux and compare the fluxes between solutes to get selectivity.
  \end{itemize}
    
  \section{Methods}
    
  We ran all MD simulations and energy minimizations using GROMACS 2018. We
  performed all post-simulation trajectory using python scripts which are available
  online at \\ \texttt{https://github.com/shirtsgroup/LLC\_Membranes}.

  \subsection{Molecular Dynamics Simulations}
  
  % BJC: Could I just reference previous work here? "MD simulations were run as 
  % described in our previous work..."

  We studied transport of solutes in the H\textsubscript{II} phase using an
  atomistic molecular model of four pores in a monoclinic unit cell with 
  10 \% water by weight. 
  \begin{itemize}
    \item Approximately one third of the water molecules occupy the tail region 
    with the rest near the pore center.
    \item We chose to study the 10 wt \% water system because solutes move 
    significantly faster than in the 5 wt \% system studied previously.
    \item Appropriate stochastic modeling requires that solutes sample the 
    accessible mechanisms with representative probability.
  \end{itemize}
  
  We chose to study a subset of 4 of the fastest moving solutes from our previous
  work: methanol, acetic acid, urea and ethylene glycol.
  \begin{itemize} 
    \item In addition to exploring membrane structural space the most, these solutes
    have a relatively diverse set of chemical functionality.   
    \item For each solute we created a separate system and to each system we
    added 6 solutes per pore for a total of 24 solutes.
    \item This number of solutes per pore provides a balance of a low 
    degree of interaction between solutes and sufficient amount of data from
    which to generate statistics on the time scales which we simulate.
    \item Further details on the setup and equilibration of these systems can
    be found in our previous work.\cite{coscia_chemically_2019}
  \end{itemize}
  
  \noindent We extended the 1 $\mu$s simulations of our previous work to 5 $\mu$s in order
  to collect ample data.
  \begin{itemize}
    \item We simulated the system with a time step of 2 fs at a pressure of 1 bar
    and 300 K controlled by the Parinello-Rahman barostat and the v-rescale thermostat
    respectively.
    \item We recorded frames every 0.5 ns
  \end{itemize}

  \subsection{The Infinite State Hidden Markov Model}\label{method:iHMM}
  %BJC: There is a fair amount of detail here just so I could understand better by writing it out
  
  Hidden Markov models (HMMs) are a useful and widely used technique
  for modeling sequences of observations where the probability of the next observation
  in a sequence depends only on a previous unobserved, latent or hidden, state.~\cite{beal_infinite_2002}
  \begin{itemize}
    \item In the context of our simulations, the observations correspond to 
    the center of mass coordinates of the solutes versus time, and the states
    correspond to the dynamical behavior which give rise to those types
    of observations.
    \item Unfortunately, standard HMMs require the number of hidden states to be known
    a priori.
    \item One can partially overcome this by testing a range of numbers of 
    hidden states and determining which is the best representation of the
    data.
  \end{itemize}
  
  %BJC: I'm not sure how much of this I should include. This is pretty much 
  % a reproduction of Fox et al's explanation: https://ieeexplore.ieee.org/abstract/document/5563110
  The infinite-state HMM overcomes this drawback by placing a hierarchical
  Dirichlet process (HDP) prior on the transition probabilities.
  \begin{itemize}
    \item Using some base probability distribution, H, a Dirichlet process 
    (DP) generates distributions over a countably infinite number of 
    probability measures:
    \begin{equation}
      G_0 = \sum_{k=1}^{\infty} \beta_k \delta_{\theta_k} ~~ \theta_k \sim H, \beta \sim GEM(\gamma)
    \end{equation}
    where the $\theta_k$ are values drawn from the base distribution and the
    weights $\beta_k$ come from a stick-breaking process parameterized by the concentration 
    parameter $\gamma$ (equivalently referred to as GEM($\gamma$)). 
    \item The concentration parameter expresses one's confidence in H relative to the posterior 
    and is closely related to the number of data observations.
    \item Each row, $G_j$, of the transition matrix is produced by drawing from a DP specified 
    using the $\beta$ vector as a discrete base distribution and a separate concentration
    parameter, $\alpha$.
    \begin{equation}
      G_j = \sum_{k=1}^{\infty} \pi_{jk} \delta_{\theta_k} ~~ \pi_j \sim DP(\alpha, \beta)
    \end{equation}
    \item This hierarchical specification ensures that the transition probabilities in 
    each row share the same support points \{$\theta_1$, ..., $\theta_k$\}.
    \item Once the model has converged only a finite number of states will have significant
    sampling.
  \end{itemize}
  
  %BJC: I do need to include this
  \noindent We describe the dynamics of each state using a vector autoregressive (VAR) model. 
  \begin{itemize}
  	\item A VAR($r$) process is characterized by a vector of observations in a time series 
  	that are linearly dependent on $r$ previous values of the time series vector:
  	\begin{equation}
  	\mathbf{y}_t = \mathbf{c} + \sum_{i=1}^r A_i\mathbf{y}_{t-i} + \mathbf{e}_t~~~~\mathbf{e}_t \sim N(0, \Sigma)
  	\end{equation}
  	Previous observations are weighted by coefficient matrices $A_i$. The VAR($r$) 
  	process is further characterized by a shift in the mean of each dimension by the
  	vector $\mathbf{c}$ and a white noise term $\mathbf{e}_t$.~\cite{hamilton_time_1994}
  	\item We assumed multivariate Gaussian noise, with mean zero and covariance, $\Sigma$.
  	\item We limited our analysis to an autoregressive order of $r=1$. %BJC: might try higher orders, but probably not worth it
  	\item We used a conjugate matrix-normal inverse-Wishart prior on parameters
  	$A$ and $\Sigma$ and a conjugate Gaussian prior on $\mathbf{c}$ in order to analytically
  	draw from the posterior.~\cite{fox_nonparametric_2009}
  \end{itemize}   
  
  %Based on the algorithms developed by Fox et al.~\cite{fox_sticky_2007}, 
  Using the iHMM framework, we estimated the most likely number and sequence of hidden states
  while simultaneously estimating VAR(1) parameters for each state and the overall 
  state transition probability matrix, $T$.
  \begin{itemize}
    \item We created a python implementation of this process which we heavily adapted from
    the MATLAB code of Fox et al.~\cite{fox_sticky_2007} 
    \item Parameter estimation is iterative. Therefore, we looked for convergence 
    as shown in SI.
    \item We refer the interested reader to much more extensive descriptions of 
    this process and its implementation. 
    ~\cite{beal_infinite_2002,teh_hierarchical_2006,van_gael_beam_2008,fox_nonparametric_2009,fox_bayesian_2010}
  \end{itemize}
  
  We generated stochastic realizations by drawing state sequences based on the
  rows of $T$. 
  %BJC: lots more implementation details once that is ironed out
  
  \subsection{Estimating Flux and Selectivity}
  %BJC: can make this discussion somewhat short since it's already in previous paper. 
  % Should probably just hit all the main equations quickly.
  
  \noindent We calculate first passage times by propagating stochastic trajectories until they
  reach distance $L$. \\
  
  We determine the mean first passage time (MFPT) using the following equation:~\cite{cussler_diffusion:_2009}
  \begin{equation}
  P(t) = -\frac{1}{\sqrt{\pi}}e^{-(L - vt)^2 / (4Dt)}\bigg(-\frac{D(L - vt)}{4(Dt)^{3/2}} - \frac{v}{2\sqrt{Dt}}\bigg)
  \label{eqn:passage_times}
  \end{equation}
  
  \noindent Flux, $J$, is simply 1 / MFPT by the Hill relation.~\cite{hill_free_1989} \\
  
  In our previous work, we showed that, in the absence of convective solute flux, selectivity
  towards solute $i$ versus solute $j$ can be calculated by:  
  \begin{equation}
  S_{ij} = \frac{J_i / \Delta C_i}{J_j / \Delta C_j}
  \label{eqn:selectivity}
  \end{equation}
  where $\Delta C_j$ is the trans-membrane concentration difference.

  \section{Results and Discussion}
  
  \noindent Trajectory realizations qualitatively match MD simulation trajectories.
  \begin{itemize}
    \item Look for hopping and trapping behavior
  \end{itemize}
  
  \noindent MSDs generated from stochastic trajectories match those from MD.
  \begin{itemize}
  	\item Look at curvature and 1-$\sigma$ confidence intervals
  \end{itemize}
  
  \noindent We can relate the identified states back to transport mechanisms.
  \begin{itemize}
  	\item More detailed discussion of identified states
  	\item How size of fluctuations, autoregressive parameters are influenced by trapping mechanisms
  	\item Any new states?
  \end{itemize}
  
  \noindent We can predict macroscopic flux and selectivity.
  \begin{itemize}
  	\item Flux as function of pore length
  	\item Selectivity as function of pore length (if flux scaling is length-dependent)
  \end{itemize}
 
  \section{Conclusion}
  
  \noindent We have shown that the iHMM can be used to parameterize solute time series
  with an unknown number of latent dynamical modes. \\
  
  \noindent We can use the iHMM to help identify mechanisms by relating the latent
  states to observed solute behavior. \\
  
  \noindent We can use the iHMM to predict macroscopic transport properties. \\
  
  \noindent The iHMM is not limited to the H\textsubscript{II} phase.
  
  \section*{Supporting Information}

  Detailed explanations and expansions upon the results and procedures mentioned in
  the main text are described in the Supporting Information. This information is
  available free of charge via the Internet at http://pubs.acs.org.

  \section*{Acknowledgements}

  Molecular simulations were performed using the Extreme Science and
  Engineering Discovery Environment (XSEDE), which is supported by National
  Science Foundation grant number ACI-1548562. Specifically, it used the Bridges
  system, which is supported by NSF award number ACI-1445606, at the Pittsburgh
  Supercomputing Center (PSC). This work also utilized the RMACC Summit supercomputer,
  which is supported by the National Science Foundation (awards ACI-1532235 and
  ACI-1532236), the University of Colorado Boulder, and Colorado State
  University. The Summit supercomputer is a joint effort of the University of
  Colorado Boulder and Colorado State University.

  \clearpage

  \bibliographystyle{ieeetr}
  \bibliography{hdphmm}

  \newpage

  \section*{TOC Graphic}

\end{document}
